{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Boosting\n",
    "#### Implementing Adaptive Boosting with a simple classifier\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "### Assignment Contents:\n",
    "- [Building a Simple Classifier](#Building-a-Simple-Binary-Tree-Classifier)\n",
    "- [Building Adaptive Boosting](#Building-Adaptive-Boosting)\n",
    "- [Census Data](#Census-Data)\n",
    "- [AdaBoost in `sklearn`](#sklearn)\n",
    "\n",
    "#### EXPECTED TIME: 4 HRS\n",
    "\n",
    "### Overview\n",
    "This assignment extends the work done in Assignment 6 with Random Forests.  \n",
    "\n",
    "Initially the assignment is theory heavy, both a simple classifier and an adaptive boosting model will be built from scratch. This will primarily involve creating `Python` implementations of the algorithms found in lectures, both this week and last week. As usual, pre-built versions of these algorithms will be demonstrated at the end of the lesson.  \n",
    "Building the algorithms from scratch help to ensure depth of theoretical knowledge before allowing `Python` and its packages to handle the heavy lifting.\n",
    "\n",
    "### Activities in this Assignment\n",
    "- Create a simple Classifier\n",
    "    - Find potential splits in data\n",
    "    - Find the best split according to entropy\n",
    "    - Create binary predictions given a chosen split\n",
    "- Create an Adaptive Boosting Algorithm\n",
    "    - Create Weights\n",
    "    - Calculate Epsilon and Alph\n",
    "    - Update Weights\n",
    "   \n",
    "- Use Adaptive Boosting to Create Predictions on Census Data\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Building a Simple Binary Tree Classifier\n",
    "\n",
    "Below, pseudo-code for a simple binary tree classifier class is provided.  \n",
    "\n",
    "The structure of this pseudo-code mimics the structure of the `sklearn` classifiers in that it creates \"fit\" and \"predict\" methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class Simple_Binary(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        \"\"\"\n",
    "            1. Find best split in X\n",
    "                - According to entropy\n",
    "            2. After finding split, assign:\n",
    "                - self.col_idx\n",
    "                - self.split_value\n",
    "                - self.left_pred\n",
    "                - self.right_pred\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            1. Make predictions given values calculated\n",
    "                in the `.fit(X,y)` method.\n",
    "            2. return predictions as numpy array.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Instead of building a class like `sklearn`, our `.fit()` and `.predict()` methods will be written as independent `simple_binary_tree_fit()` and `simple_binary_tree_predict()` functions.\n",
    "\n",
    "In `simple_binary_tree_fit`, **3 steps** must be accomplished:  \n",
    "\n",
    "1. Find all of the potential values for splitting.\n",
    "2. Find the column and split_value that results in the lowest entropy.\n",
    "3. Given that \"best split\", determine which predictions should be made when data is \"<=\" and \">\" that split value.  \n",
    "\n",
    "The below provides framework for returning the column and split value that yeilds the lowest entropy, and the predictions indicated by that split.  \n",
    "After correctly defining `find_splits()`, `ent_from_split()`, and `pred_from_split()` -- marked with \"`### <------`\" -- the `simple_binary_tree_fit()` function should work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def simple_binary_tree_fit(X,y):\n",
    "    \"\"\"\n",
    "    \n",
    "    Positional arguments -\n",
    "        X -- a numpy array of numeric observations:\n",
    "            Assume rows are separate observations, columns are features\n",
    "        y -- a numpy array of binary labels:\n",
    "            *Assume labels are 1 for \"True\" and 0 for \"False\"*\n",
    "            \n",
    "    1. Find best split in X\n",
    "        - According to entropy\n",
    "    2. After finding split, return:\n",
    "        - col_idx - index of column used to split data\n",
    "        - split_value - value upon which data is split\n",
    "        - left_pred - The prediction for observation <= split_value\n",
    "        - right_pred - The prediciton for observation > split_value\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # create variable \"best_split\" which will hold:\n",
    "    # (col_number, split_value, entropy)\n",
    "    best_split = (-1,-1,1)\n",
    "    \n",
    "    # loop through each column in X, keeping track of the column index.\n",
    "    # # # Note, taking the transpose of X -- X.T -- yeilds columns in this \"for\" loop\n",
    "    for col_idx, col in enumerate(X.T):\n",
    "        \n",
    "        # Find potential split values within column using `find_splits(col)`\n",
    "        splits = find_splits(col) ### <------\n",
    "        \n",
    "        # For each split, calculate entropy\n",
    "        for s in splits:\n",
    "            ent = ent_from_split(col, s, y) ### <------\n",
    "            \n",
    "            # Check if calculated entropy is less than previous \"best\"\n",
    "            if ent < best_split[2]:\n",
    "                best_split = (col_idx, s, ent)\n",
    "    \n",
    "    # Now, the \"best split\" has been found.\n",
    "    # create \"left\" and \"right\" predictions for the best_split\n",
    "    # The \"left\" predictions is for when `observation` <= `split_value`\n",
    "    # The \"right\" prediction is for when `observation` > `split_value`\n",
    "    # Each prediction will either be 1 for \"True\" or 0 for \"False\"\n",
    "    \n",
    "    left_pred, right_pred = pred_from_split(X, y, *best_split[:2]) ### <------\n",
    "    \n",
    "    col_idx, split_value = best_split[:2]\n",
    "    \n",
    "    # return:\n",
    "    # - the index of the column to split on.\n",
    "    # - the value to split that column on\n",
    "    # - the prediction for rows with observations in that column less than or equal to the split\n",
    "    # - the prediction for rows with observations in that column greater than the split\n",
    "    \n",
    "    return col_idx, split_value, left_pred, right_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Build the `find_splits()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_splits(col):\n",
    "    \"\"\"\n",
    "    Calculate and return all possible split values given a column of numeric data\n",
    "    \n",
    "    Positional argument:\n",
    "        col -- a 1-dimensional numpy array, corresponding to a numeric\n",
    "            predictor variable.\n",
    "    \n",
    "    Example:\n",
    "        col = np.array([0.5, 1. , 3. , 2. , 3. , 3.5, 3.6, 4. , 4.5, 4.7])\n",
    "        splits  = find_splits(col)\n",
    "        print(splits) # --> np.array([0.75, 1.5, 2.5, 3.25, 3.55, 3.8, 4.25, 4.6])\n",
    "        \n",
    "    \"\"\"\n",
    "    def swap(num1,num2):\n",
    "        num1,num2 = num2,num1\n",
    "        return num1,num2\n",
    "    \n",
    "    def bubble(x):\n",
    "        for i in range(0,len(x)):\n",
    "            for j in range(0,len(x)-i-1):\n",
    "                if x[j]>x[j+1]:\n",
    "                    x[j+1],x[j] = swap(x[j+1],x[j])\n",
    "        return x\n",
    "    \n",
    "    sorted_array = np.unique(bubble(col))\n",
    "    \n",
    "    y = [float((sorted_array[i]+sorted_array[i+1])/2) for i in range(len(sorted_array)-1)]\n",
    "    \n",
    "    splits = np.array(y)\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Equation for Entropy for binary classification at binary split:\n",
    "The entropy at a node containing only two classes is calculated by:\n",
    "\n",
    "$Entropy(node) = -p_{class1}*log_2(p_{class1}) + -p_{class2}*log_2(p_{class2})$  \n",
    "\n",
    "Suppose a node contains the observations [1,0,1,1]. Then:  \n",
    "\n",
    "$Entropy(node) = -p_{class1}*log_2(p_{class1}) + -p_{class2}*log_2(p_{class2})$  \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = -.75*log_2(.75) + -.25*log_2(.25)$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = .311 + .5$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\approx .811$  \n",
    "\n",
    "\n",
    "This calculation is already programmed into the supplied `entropy()` function below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "def entropy(class1_n, class2_n):\n",
    "    # If all of one category, log2(0) does not exist,\n",
    "    # and entropy = 0\n",
    "    if (class1_n == 0) or (class2_n == 0):\n",
    "        return 0\n",
    "\n",
    "    # Find total number of observations \n",
    "    total = class1_n + class2_n\n",
    "\n",
    "    # find proportion of both classes\n",
    "    class1_proprtion = class1_n/total\n",
    "    class2_proportion = class2_n/total\n",
    "\n",
    "    # implement entropy function\n",
    "    return  sum([-1 * prop * np.log2(prop)\n",
    "                 for prop in [class1_proprtion, class2_proportion] ])\n",
    "\n",
    "print(entropy(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The entropy of a split is:  \n",
    "$Entropy(split) = p_{node1} * Entropy(node1)+ p_{node2}* Entropy(node2)$  \n",
    "\n",
    "\n",
    "Where $p_{node}$ is the proportion of observations at that node\n",
    "\n",
    "Suppose:  \n",
    "Node 1 contains the observations - [1,0,1,1]  \n",
    "Node 2 contains the observations - [0,0,0,1,1,0]\n",
    "\n",
    "Then:  \n",
    "$Entropy(split) = p_{node1} * Entropy(node1)+ p_{node2}* Entropy(node2)$  \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = .4 *Entropy(node1) + .6 * Entropy(node2)$\n",
    "\n",
    "--------------------------------  \n",
    "\n",
    "For our purposes, the two classes in each node will be defined by:\n",
    "1. Observations with values less than or equal to the split value  \n",
    "2. Observations with values greater than the split value.\n",
    "\n",
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ent_from_split(col, split_value, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the entropy of a split.\n",
    "    \n",
    "    Positional arguments:\n",
    "        col -- a 1-dimensional numpy array, corresponding to a numeric\n",
    "            predictor variable.\n",
    "        split_value --  number, defining where the spliting should occur\n",
    "        labels -- a 1-dimensional numpy array, corresponding to the class\n",
    "            labels associated with the observations in `col`.\n",
    "            assume they will be \"0\"s and \"1\"s\n",
    "    Example:\n",
    "        col = np.array([1,1,2,2,3,3,4])\n",
    "        split = 2.5\n",
    "        labels = np.array([0,1,0,0,1,0,1])\n",
    "        \n",
    "        ent = ent_from_split(col, split, labels)\n",
    "        \n",
    "        print(ent) # --> 0.8571428571428571\n",
    "    \n",
    "    \"\"\"\n",
    "    if (split_value > max(col)) or (split_value < min(col)):\n",
    "        return 'Split outside the range of the column values'\n",
    "    \n",
    "    \n",
    "    idx_less,idx_great = np.where(col< split_value )[0] , np.where(col>split_value )[0]\n",
    "    \n",
    "    left, right = labels[idx_less], labels[idx_great] #index positions of the split\n",
    "    \n",
    "    # right split counts for each class\n",
    "    class1_right, class2_right = len(right[right == 1]) , len(right[right == 0])\n",
    "    # left split counts for each class\n",
    "    class1_left, class2_left = len(left[left == 1]) , len(left[left == 0])\n",
    "    #right node entropy\n",
    "    right = entropy(class1_right, class2_right)\n",
    "    #left node entropy\n",
    "    left = entropy(class1_left, class2_left)\n",
    "    #right node proportion\n",
    "    print((class1_right + class2_right))\n",
    "    p_right = (class1_right + class2_right)/len(col)\n",
    "    #left node proportion\n",
    "    print((class1_left  + class2_left))\n",
    "    p_left = (class1_left  + class2_left)/len(col)\n",
    "    print(len(col))\n",
    "    #entropy gain\n",
    "    ent = p_right*right + p_left*left    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3\n",
    "\n",
    "Creating predictions from the observed majority class at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_from_split(X, y, col_idx, split_value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return predictions for the nodes defined by the given split.\n",
    "    \n",
    "    Positional argument:\n",
    "        X -- a 2-dimensional numpy array of predictor variable observations.\n",
    "            rows are observations, columns are features.\n",
    "        y -- a 1-dimensional numpy array of labels, associated with observations\n",
    "             in X.\n",
    "        col_idx -- an integer index, such that X[:,col_idx] yeilds all the observations\n",
    "            of a single feature.\n",
    "        split_value -- a numeric split, such that the values of X[:,col_idx] that are\n",
    "            <= split_value are in the left node. Those > split_value are in the right node.\n",
    "    \n",
    "    Example:\n",
    "        X = np.array([[0.5, 3. ], [1.,  2. ], [3.,  0.5],\n",
    "                      [2.,  3. ], [3.,  4. ]])\n",
    "            \n",
    "        y = np.array([ 1, 1, 0, 0, 1])\n",
    "        \n",
    "        col_idx = 0\n",
    "        \n",
    "        split_value = 1.5\n",
    "        \n",
    "        pred_at_nodes = pred_from_split(X, y, col_idx, split_value)\n",
    "        print(pred_at_nodes) # --> (1, 0)\n",
    "\n",
    "    \"\"\"\n",
    "    if (split_value > max(X[:,col_idx])) or (split_value < min(X[:,col_idx])):\n",
    "        return 'Split outside the range of the column values'\n",
    "    \n",
    "    \n",
    "    idx_less,idx_great = np.where(X[:,col_idx]< split_value )[0] , np.where(X[:,col_idx]>split_value )[0]\n",
    "    \n",
    "    left, right = y[idx_less], y[idx_great] #index positions of the split\n",
    "    \n",
    "    # right split counts for each class\n",
    "    class1_right, class0_right = right[right == 1] , right[right == 0]\n",
    "    # left split counts for each class\n",
    "    class1_left, class0_left = left[left == 1] , left[left == 0]\n",
    "    \n",
    "    print('the index positions for split {} are {} , {} '.format(split_value,idx_less,idx_great))\n",
    "    print('for the left split, these are the y vals: {} \\n for the right split, these are the y vals: {}'.format(left,right))\n",
    "    print('the count for right split class1: {} and class0: {}'.format(class1_right, class0_right))\n",
    "    print('the count for left split class1: {} and class0: {}'.format(class1_left, class0_left))\n",
    "    \n",
    "    if (len(class1_right) == len(class0_right)) and (len(class1_left) == len(class0_left)):\n",
    "        left_pred, right_pred = 1 , 1\n",
    "        return (left_pred, right_pred)\n",
    "    \n",
    "    elif (len(class1_right) == len(class0_right)):\n",
    "        left_pred, right_pred = 1 , 0\n",
    "        return (left_pred, right_pred)\n",
    "    elif (len(class1_left) == len(class0_left)):\n",
    "        left_pred, right_pred = 0 , 1\n",
    "        return (left_pred, right_pred)\n",
    "    else:\n",
    "        left1, right1 = 1,1\n",
    "        left0, right0 = 0,0\n",
    "        if len(class1_right) > len(class0_right):\n",
    "            right_pred = right1\n",
    "        if len(class1_right) < len(class0_right):\n",
    "            right_pred = right0\n",
    "        if len(class1_left) > len(class0_left):\n",
    "            left_pred = left1\n",
    "        if len(class1_left) < len(class0_left):\n",
    "            left_pred = left0        \n",
    "    \n",
    "    return (left_pred,right_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 4\n",
    "Creating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_binary_tree_predict(X, col_idx, split_value, left_pred, right_pred):\n",
    "    \"\"\"\n",
    "    Create an array of predictions built from: observations in one column of X,\n",
    "        a given split value, and given predictions for when observations\n",
    "        are less-than-or-equal-to that split or greater-than that split value\n",
    "        \n",
    "    Positional arguments:\n",
    "        X -- a 2-dimensional numpy array of predictor variable observations.\n",
    "            rows are observations, columns are different features\n",
    "        col_idx -- an integer index, such that X[:,col_idx] yeilds all the observations\n",
    "            in a single feature.\n",
    "        split_value -- a numeric split, such that the values of X[:,col_idx] that are\n",
    "            <= split_value are in the left node, and those > are in the right node.   \n",
    "        left_pred -- class (0 or 1), that is predicted when observations\n",
    "            are less-than-or-equal-to the split value\n",
    "        right_pred -- class (0 or 1), that is predicted when observations\n",
    "            are greater-than the split value\n",
    "            \n",
    "    Example:\n",
    "        X = np.array([[0.5, 3. ], [1.,  2. ], [3.,  0.5],\n",
    "                [2.,  3. ], [3.,  4. ]])\n",
    "        col_idx = 0\n",
    "        split_value = 1.5\n",
    "        left_pred = 1\n",
    "        right_pred = 0\n",
    "\n",
    "        preds = simple_binary_tree_predict(X, col_idx, split_value, left_pred, right_pred)\n",
    "\n",
    "        print(preds) #--> np.array([1,1,0,0,0])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    for i in X[:,col_idx]:\n",
    "        if i >= split_value:\n",
    "            res.append(right_pred)\n",
    "        else:\n",
    "            res.append(left_pred)\n",
    "    \n",
    "    return np.array([res])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "At this point, we have a functioning binary-tree classifier that can be fit on data, and then given that fit, make predictions on out-of-sample data.  \n",
    "\n",
    "However, our ultimate goal is creation of an Adaptive Boosting algorithm.  \n",
    "\n",
    "\n",
    "Our Adaptive Boosting algorithm's prediction for out of sample data will be:  \n",
    "\n",
    "$$f_{boost}(x_0) = sign(\\sum_{t=1}^T\\alpha_tf_t(X_0))$$  \n",
    "\n",
    "The alpha is equal to:\n",
    "$$\\alpha_t = \\frac12ln(\\frac{1-\\epsilon_t}{\\epsilon_t})$$  \n",
    "\n",
    "The Epsilon is equal to:  \n",
    "\n",
    "$$\\epsilon_t = \\sum_{i=1}^nw_t(i)\\mathbb{1}\\{y_i\\ne f_t(x_i)\\}$$  \n",
    "\n",
    "Where all weights starts at$\\frac1n$  \n",
    "\n",
    "And weights update by:\n",
    "$$w_{t+1}(i) = \\frac{\\hat{w}_{t+1}(i)}{\\sum_j\\hat{w}_{t+1}(j)}$$  \n",
    "\n",
    "Where:\n",
    "$$\\hat{w}_{t+1}(i) = w_t(i)e^{-\\alpha_ty_if_t(x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "While we could use the `simple_binary_tree` functions created above, in the interest of speed, we will use sklearn's `DecisionTreeClassifier` as a the simple predictor to boost.\n",
    "\n",
    "The below gives a short example of using `DecisionTreeClassifier` that:  \n",
    "\n",
    "- Splits toy data in two\n",
    "- Builds two Trees each on 1/2 of data\n",
    "- Saves each tree with an associated \"alpha\" in a dictionary (As will be done in boosting)\n",
    "- Creates predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2c88dc8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "      x    y  classification\n",
      "0  0.5  3.0               1\n",
      "1  1.0  2.0               1\n",
      "2  3.0  0.5              -1\n",
      "3  2.0  3.0              -1\n",
      "4  3.0  4.0               1\n",
      "5  3.5  2.5              -1\n",
      "6  3.6  4.7               1\n",
      "7  4.0  4.2               1\n",
      "8  4.5  2.0              -1\n",
      "9  4.7  4.5              -1 \n",
      "\n",
      "threshold: 1.5 feature: 0\n",
      "threshold: 4.25 feature: 0\n",
      "\n",
      "tree1 predictions on all elements: [1 1 0 0 0 0 0 0 0 0]\n",
      "tree2 predictions on all elements: [1 1 1 1 1 1 1 1 0 0]\n",
      "\n",
      "Entropy of different splits for observations 5-9\n",
      "3\n",
      "2\n",
      "5\n",
      "Col 1, @ 3.35: 0.5509775004326937\n",
      "2\n",
      "3\n",
      "5\n",
      "Col 0, # 4.25: 0.5509775004326937\n"
     ]
    }
   ],
   "source": [
    "### This helper function will return an instance of a `DecisionTreeClassifier` with\n",
    "### our specifications - split on entropy, and grown to depth of 1.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def simple_tree():\n",
    "    return DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "\n",
    "\n",
    "### Our example dataset, inspired from lecture\n",
    "pts = [[.5, 3,1],[1,2,1],[3,.5,-1],[2,3,-1],[3,4,1],\n",
    " [3.5,2.5,-1],[3.6,4.7,1],[4,4.2,1],[4.5,2,-1],[4.7,4.5,-1]]\n",
    "\n",
    "df = pd.DataFrame(pts, columns = ['x','y','classification'])\n",
    "\n",
    "# Plotting by category\n",
    "\n",
    "b = df[df.classification ==1]\n",
    "r = df[df.classification ==-1]\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.scatter(b.x, b.y, color = 'b', marker=\"+\", s = 400)\n",
    "plt.scatter(r.x, r.y, color = 'r', marker = \"o\", s = 400)\n",
    "plt.title(\"Categories Denoted by Color/Shape\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"df:\\n\",df, \"\\n\")\n",
    "\n",
    "### split out X and y\n",
    "X = df[['x','y']]\n",
    "\n",
    "# Change from -1 and 1 to 0 and 1\n",
    "y = np.array([1 if x == 1 else 0 for x in df['classification']])\n",
    "\n",
    "### Split data in half\n",
    "X1 = X.iloc[:len(X.index)//2, :]\n",
    "X2 = X.iloc[len(X.index)//2:, :]\n",
    "\n",
    "y1 = y[:len(y)//2]\n",
    "y2 = y[len(X)//2:]\n",
    "\n",
    "\n",
    "### Fit classifier to both sets of data, save to dictionary:\n",
    "\n",
    "tree_dict = {}\n",
    "\n",
    "tree1 = simple_tree()\n",
    "tree1.fit(X1,y1)\n",
    "print(\"threshold:\", tree1.tree_.threshold[0], \"feature:\", tree1.tree_.feature[0])\n",
    "\n",
    "### made up alpha, for example\n",
    "alpha1 = .6\n",
    "tree_dict[1] = (tree1, alpha1)\n",
    "\n",
    "tree2 = simple_tree()\n",
    "tree2.fit(X2,y2)\n",
    "print(\"threshold:\", tree2.tree_.threshold[0], \"feature:\" ,tree2.tree_.feature[0])\n",
    "\n",
    "### made up alpha, again.\n",
    "alpha2 = .35\n",
    "\n",
    "tree_dict[2] = (tree2, alpha2)\n",
    "\n",
    "### Create predictions using trees stored in dictionary\n",
    "print(\"\\ntree1 predictions on all elements:\", tree_dict[1][0].predict(X))\n",
    "print(\"tree2 predictions on all elements:\", tree_dict[2][0].predict(X))\n",
    "\n",
    "### Showing Ent\n",
    "print(\"\\nEntropy of different splits for observations 5-9\")\n",
    "print(\"Col 1, @ 3.35:\", ent_from_split(X2.iloc[:,1].values,3.35, y2))\n",
    "print(\"Col 0, # 4.25:\", ent_from_split(X2.iloc[:,0].values, 4.25, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Running the above cell a number of times, you might notice that the threshold and feature for `tree2` change.  \n",
    "\n",
    "At the bottom of the cell, the entropy for two different splits is shown to be identical. This is unlikely to happen with \"real\" data.  \n",
    "\n",
    "#### Bootstrapping\n",
    "\n",
    "Taking a bootstrap sample in adaptive boosting requires selecting observation with pre-defined probabilities.  \n",
    "\n",
    "\n",
    "Below offers an example of selecting random numbers with numpy given pre-defined probabilities.  \n",
    "\n",
    "This will be done with `np.random.choice()`, documentation below:\n",
    "![choice Documentation](./assets/npChoicProbs.PNG)  \n",
    "\n",
    "Try running the below cell a few times, to gain a sense of how `.choice()` works while passing a value for the `<p>` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting from: [0, 1, 2, 3, 4] \n",
      "\n",
      "Equal Weights:\n",
      " [0 1 0 0 2]\n",
      "\n",
      "Weights of [.9,.05,.03,.02,0]:\n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "select_from = list(range(5))\n",
    "print(\"selecting from:\", select_from, \"\\n\")\n",
    "\n",
    "### Implement 1/n weights (which is the np.random.choice default)\n",
    "### Also note:\n",
    "### replace = True (default, used for boot-strapping)\n",
    "### size = len(array) - This will be the sample size used in our algorithms.\n",
    "\n",
    "print(\"Equal Weights:\\n\",\n",
    "    np.random.choice(select_from,\n",
    "                size = len(select_from),\n",
    "                replace = True,\n",
    "                p = np.array([.2,.2,.2,.2,.2,])\n",
    "                )\n",
    ")\n",
    "\n",
    "### Now, using uneven weights\n",
    "\n",
    "print(\"\\nWeights of [.9,.05,.03,.02,0]:\\n\",\n",
    "    np.random.choice(select_from,\n",
    "                size = len(select_from),\n",
    "                p = np.array([.9,.05,.03,.02,0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Building Adaptive Boosting\n",
    "\n",
    "Below Gives the outline of the fitting process for the adaptive boosting algorithm.  \n",
    "\n",
    "Again, the functions next to \"`###<------`\" will be created in the exercises below. They include:  \n",
    "\n",
    "- `default_weights()`\n",
    "- `calc_epsilon()`\n",
    "- `calc_alpha()`\n",
    "- `update_weights()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def simple_adaboost_fit(X,y, n_estimators):\n",
    "    \"\"\"\n",
    "    Positional arguments :\n",
    "        X -- a numpy array of numeric observations:\n",
    "            rows are observations, columns are features\n",
    "        y -- a numpy array of binary labels:\n",
    "            *Assume labels are 1 for \"True\" and 0 for \"False\"*\n",
    "        estimator -- a model capable of binary classification, implementing\n",
    "            the `.fit()` and `.predict()` methods.\n",
    "        n_estimators -- The number of estimators to fit.\n",
    "\n",
    "    Steps:\n",
    "        1. Create probability weights for selection during boot-straping.\n",
    "        2. Create boot-strap sample of observations according to weights\n",
    "        3. Fit estimator model with boot-strap sample.\n",
    "        4. Calculate model error: epsilon\n",
    "        5. Calculate alpha to associate with model\n",
    "        6. Re-calculate probability weights\n",
    "        7. Repeat 2-6 unil creation of n_estimators models. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def simple_tree():\n",
    "        return DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "    \n",
    "    # Create default weights array where all are equal to 1/n\n",
    "    weights = default_weights(len(y)) ### <------\n",
    "    \n",
    "    est_dict = {}\n",
    "    for i in range(n_estimators):\n",
    "        # Create bootstrap sample\n",
    "        bs_X, bs_y = boot_strap_selection(X, y, weights)\n",
    "        \n",
    "        mod = simple_tree()\n",
    "        mod.fit(bs_X, bs_y)\n",
    "        \n",
    "        # Note: Predicting on all values of X, NOT boot-strap\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        epsilon = calc_epsilon(y, preds, weights) ### <------\n",
    "        alpha = calc_alpha(epsilon) ### <------\n",
    "        \n",
    "        # Note that the i+1-th model will be keyed to the int i,\n",
    "        # and will store a tuple of the fit model and the alpha value\n",
    "        est_dict[i] = (mod, alpha)\n",
    "        \n",
    "        weights = update_weights(weights, alpha, y, preds) ### <------\n",
    "    \n",
    "    return est_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 5\n",
    "Creating vector of default weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_weights(n):\n",
    "    \"\"\"\n",
    "    Create the default list of weights, a numpy array of length n\n",
    "    with each value equal to 1/n\n",
    "    \n",
    "    Example:\n",
    "        n = 10\n",
    "        dw = default_weights(n)\n",
    "        print(dw) #--> np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "        \n",
    "    \"\"\"\n",
    "    lst = [1/n for i in range(n)]\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### boot_strap_selection  \n",
    "\n",
    "Below, the \"`boot_strap_selection`\" algorithm is provided. The function creates a boot-strap sample given the passed-in weights.  \n",
    "\n",
    "Example given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[3, 3],\n",
      "       [5, 5],\n",
      "       [5, 5],\n",
      "       [1, 1],\n",
      "       [1, 1]]), array([1, 1, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "def boot_strap_selection(X, y, weights):\n",
    "    \"\"\"\n",
    "    Create and return a boot-strapped sample of the given data,\n",
    "    According to the provided weights.\n",
    "    \n",
    "    Positional Arguments:\n",
    "        X -- a numpy array, corresponding to the matrix of x-observations\n",
    "        y -- a numpy array, corresponding to a vector of y-labels\n",
    "            All either 0 or 1\n",
    "        weights -- a numpy array, corresponding to the rate at which the observations\n",
    "            should be sampled for the boot-strap. \n",
    "            \n",
    "    Example: \n",
    "    \n",
    "        X = np.array([[1,1],[2,2],[3,3],[4,4],[5,5]])\n",
    "        y = np.array([1,0,1,0,1])\n",
    "        weights = np.array([.35,.1,.1,.35,.1])\n",
    "        \n",
    "        print(boot_strap_selection(X,y, weights))\n",
    "        #-->(\n",
    "            np.array([[4, 4],\n",
    "                   [2, 2],\n",
    "                   [4, 4],\n",
    "                   [5, 5],\n",
    "                   [5, 5]]),\n",
    "            np.array([0, 0, 0, 1, 1]))\n",
    "        ### Actual results will vary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take random sample of indicies, with replacement\n",
    "    bss_indicies = np.random.choice(range(len(y)), size = len(y), p = weights)\n",
    "    \n",
    "    # Subset arrays with indicies\n",
    "    return X[bss_indicies,:], y[bss_indicies]\n",
    "\n",
    "### Example of use\n",
    "X = np.array([[1,1],[2,2],[3,3],[4,4],[5,5]])\n",
    "y = np.array([1,0,1,0,1])\n",
    "weights = np.array([.35,.1,.1,.35,.1])\n",
    "\n",
    "print(boot_strap_selection(X,y, weights))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6\n",
    "Calculating Epsilon\n",
    "\n",
    "The Epsilon is equal to:  \n",
    "$$\\epsilon_t = \\sum_{i=1}^nw_t(i)\\mathbb{1}\\{y_i\\ne f_t(x_i)\\}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_epsilon(y_true, y_pred, weights):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the value of epsilon, given the above equation \n",
    "    \n",
    "    Positional Arguments:\n",
    "        y_true -- An np.array of 1's and 0's corresponding to whether each observation is\n",
    "            a member of class 1 or class 2\n",
    "        y_pred -- An np.array of 1's and 0's corresponding to whether each observation was\n",
    "            predicted to be a member of class 1 or class 2\n",
    "        weights -- An np.array of floats corresponding to each observation's weight. \n",
    "            All the weights will sum up to 1.\n",
    "            \n",
    "    Example:\n",
    "        y_true = np.array([1,0,1,1,0])\n",
    "        y_pred = np.array([0,0,0,1,0])\n",
    "        weights = np.array([.4,.4,.1,.05,.05])\n",
    "        \n",
    "        ep = calc_epsilon(y_true, y_pred, weights)\n",
    "        \n",
    "        print(ep) # --> .5\n",
    "        \n",
    "    Assumptions:\n",
    "        Assume both the true labels and the predictions are both all 0's and 1's.\n",
    "    \"\"\"\n",
    "    \n",
    "    return weights[y_true != y_pred].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7\n",
    "Calculating alpha.\n",
    "\n",
    "Alpha is equal to:\n",
    "$$\\alpha_t = \\frac12ln(\\frac{1-\\epsilon_t}{\\epsilon_t})$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_alpha(epsilon):\n",
    "    \"\"\"\n",
    "    Calculate the alpha value given the epsilon observed from a model\n",
    "    \n",
    "    Positional Argument:\n",
    "        epsilon -- The epsilon value calculated from a particular model\n",
    "    Example:\n",
    "        ep = .4\n",
    "        alpha = calc_alpha(ep)\n",
    "        print(alpha) # --> 0.2027325540540821\n",
    "    \"\"\"\n",
    "    if epsilon < 0:\n",
    "        return 'need non-neg eps you fool'\n",
    "    if epsilon == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    alphie = np.log(((1-epsilon)/epsilon))\n",
    "    final = .5*alphie\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 8\n",
    "Updating weights\n",
    "\n",
    "To update weights:\n",
    "$$w_{t+1}(i) = \\frac{\\hat{w}_{t+1}(i)}{\\sum_j\\hat{w}_{t+1}(j)}$$  \n",
    "\n",
    "Where:\n",
    "$$\\hat{w}_{t+1}(i) = w_t(i)e^{-\\alpha_ty_if_t(x_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(weights, alpha, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Create an updated vector of weights according to the above equations\n",
    "    \n",
    "    Positional Arguments:\n",
    "        weights -- a 1-d numpy array of positive floats, corresponding to \n",
    "            observation weights\n",
    "        alpha -- a positive float\n",
    "        y_true -- a 1-d numpy array of true labels, all 0s and 1s\n",
    "        y_pred -- a 1-d numpy array of labels predicted by the last model;\n",
    "             all 0s and 1s. \n",
    "    \n",
    "    Example:\n",
    "        y_true = np.array([1,0,1,1,0])\n",
    "        y_pred = np.array([0,0,1,1,1])\n",
    "        weights = np.array([.4,.4,.1,.05,.05])\n",
    "        alpha = 0.10033534773107562\n",
    "        \n",
    "        print(update_weights(weights, alpha, y_true, y_pred))\n",
    "        #-->np.array([0.44444444 0.36363636 0.09090909 0.04545455 0.05555556])\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def target_for_weight_update(y):\n",
    "        toRet = y.copy()\n",
    "        toRet[toRet == 0] = -1\n",
    "        return toRet\n",
    "    # convert predictions and actual labels to 1's and -1's\n",
    "    y = target_for_weight_update(y_true)\n",
    "    pred = target_for_weight_update(y_pred)\n",
    "    #print(\"sol:\", y[:10], pred[:10])\n",
    "    # implement weight update equation\n",
    "    weights = weights * np.e**(-alpha*y*pred)\n",
    "    #print(\"sol:\",-alpha*y*pred)\n",
    "    # normalize weights by dividing by sum of all weights\n",
    "    weights = weights / sum(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "With the above functions created, the \"`simple_adaboost_fit()`\" method should work correctly.  \n",
    "\n",
    "`simple_adaboost_fit()` returns a dictionary where the keys are 0 through n-1 where n is the `n_estimators` from the function signature.  \n",
    "\n",
    "The values of the dictionaries are (model, alpha) where `model`is a `DecisionTreeClassifier`, and `alpha` is a float.  \n",
    "\n",
    "#### Question 9\n",
    "Creating a Prediction from boosted trees\n",
    "\n",
    "Our prediction will be:  \n",
    "\n",
    "$$f_{boost}(x_0) = sign(\\sum_{t=1}^T\\alpha_tf_t(X_0))$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, est_dict):\n",
    "    \"\"\"\n",
    "    Create a np.array list of predictions for all of the observations in x,\n",
    "    according to the above equation.\n",
    "    \n",
    "    Positional Arguments:\n",
    "        X -- a 2-d numpy array of X observations. Features in columns, \n",
    "            observations in rows.\n",
    "        est_dict -- a dictionary consists of keys 0 through n with tuples as values\n",
    "            The tuples will be (<mod>, alpha), where alpha is a float, and \n",
    "            <mod> is a sklearn DecisionTreeClassifier\n",
    "    Example:\n",
    "    \n",
    "        ### Our example dataset, inspired from lecture\n",
    "        pts = [[.5, 3,1],[1,2,1],[3,.5,0],[2,3,0],[3,4,1],\n",
    "         [3.5,2.5,0],[3.6,4.7,1],[4,4.2,1],[4.5,2,0],[4.7,4.5,0]]\n",
    "\n",
    "        df = pd.DataFrame(pts, columns = ['x','y','classification'])\n",
    "        \n",
    "        ### split out X and labels\n",
    "        X = df[['x','y']]\n",
    "        y = df['classification']\n",
    "        ### Split data in half\n",
    "        X1 = X.iloc[:len(X.index)//2, :]\n",
    "        X2 = X.iloc[len(X.index)//2:, :]\n",
    "\n",
    "        y1 = y[:len(y)//2]\n",
    "        y2 = y[len(X)//2:]\n",
    "\n",
    "\n",
    "        ### Fit classifiers to both sets of data, save to dictionary:\n",
    "        \n",
    "        ### Tree-creator helper function\n",
    "        def simple_tree():\n",
    "            return DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "            \n",
    "        tree_dict = {}\n",
    "\n",
    "        tree1 = simple_tree()\n",
    "        tree1.fit(X1,y1)\n",
    "        print(\"threshold:\", tree1.tree_.threshold[0], \"feature:\", tree1.tree_.feature[0])\n",
    "\n",
    "        ### made up alpha, for example\n",
    "        alpha1 = .6\n",
    "        tree_dict[1] = (tree1, alpha1)\n",
    "\n",
    "        tree2 = simple_tree()\n",
    "        tree2.fit(X2,y2)\n",
    "        print(\"threshold:\", tree2.tree_.threshold[0], \"feature:\" ,tree2.tree_.feature[0])\n",
    "        \n",
    "        ### made up alpha, again.\n",
    "        alpha2 = .35\n",
    "        tree_dict[2] = (tree2, alpha2)\n",
    "    \n",
    "        print(predict(X, tree_dict))\n",
    "        #--> np.array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        \n",
    "        ###############################\n",
    "        ### For Further Checking of your function:\n",
    "        ### The sum of predictions from the two models should be:\n",
    "        \n",
    "        # If tree2 splits on feature 1:\n",
    "        # np.array([ 0.25  0.25 -0.95 -0.95 -0.25 -0.95 -0.25 -0.25 -0.95 -0.25])\n",
    "        \n",
    "        # If tree2 splits on feature 0:\n",
    "        # np.array([ 0.95  0.95 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.95 -0.95])\n",
    "        ###############################\n",
    "        \n",
    "    Assumptions:\n",
    "        The models in the `est-dict` tuple will return 0s and 1s.\n",
    "            HOWEVER, the prediction equation depends upon predictions\n",
    "            of -1s and 1s.\n",
    "            FINALLY, the returned predictions should be 0s and 1s.            \n",
    "    \"\"\"\n",
    "    fin_preds = np.zeros(X.shape[0])\n",
    "    for k in est_dict:\n",
    "        preds = est_dict[k][0].predict(X)\n",
    "        preds[preds<1] = -1\n",
    "        #print(preds, est_dict[k][1])\n",
    "        preds = preds *est_dict[k][1]\n",
    "        fin_preds += preds\n",
    "        #print(fin_preds)\n",
    "    fin_preds[fin_preds >= 0 ] = 1\n",
    "    fin_preds[fin_preds <0] = 0\n",
    "        \n",
    "    return fin_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Census Data\n",
    "This assignment will use the [**`Census Income Data`**](https://archive.ics.uci.edu/ml/datasets/census+income) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.html). A thorough description of the data and its features may be accessed either at the link above, or [this text file](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names).  \n",
    "\n",
    "In particular, this classification attempts to predict whether or not a particular census respondant has an income of more or less than $50,000.  \n",
    "  \n",
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\n",
    "\"age\", \"workclass\", \"fnlwgt\", \"education\",\n",
    "\"education-num\", \"marital-status\", \"occupation\", \"relationship\",\n",
    "\"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\",\n",
    "\"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "data_path = \"../resource/asnlib/publicdata/adult.data\"\n",
    "\n",
    "data = pd.read_csv(data_path, header = None, names = col_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Taking a subset of the data relevant to the prediction problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  education-num          occupation      sex  \\\n",
       "0   39          State-gov             13        Adm-clerical     Male   \n",
       "1   50   Self-emp-not-inc             13     Exec-managerial     Male   \n",
       "2   38            Private              9   Handlers-cleaners     Male   \n",
       "3   53            Private              7   Handlers-cleaners     Male   \n",
       "4   28            Private             13      Prof-specialty   Female   \n",
       "\n",
       "   hours-per-week  income  \n",
       "0              40   <=50K  \n",
       "1              13   <=50K  \n",
       "2              40   <=50K  \n",
       "3              40   <=50K  \n",
       "4              40   <=50K  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"age\", \"workclass\", \"education-num\", \"occupation\", \"sex\", \"hours-per-week\", \"income\"]\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4140</td>\n",
       "      <td>21790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass  education-num       occupation    sex  \\\n",
       "count   32561.000000     32561   32561.000000            32561  32561   \n",
       "unique           NaN         9            NaN               15      2   \n",
       "top              NaN   Private            NaN   Prof-specialty   Male   \n",
       "freq             NaN     22696            NaN             4140  21790   \n",
       "mean       38.581647       NaN      10.080679              NaN    NaN   \n",
       "std        13.640433       NaN       2.572720              NaN    NaN   \n",
       "min        17.000000       NaN       1.000000              NaN    NaN   \n",
       "25%        28.000000       NaN       9.000000              NaN    NaN   \n",
       "50%        37.000000       NaN      10.000000              NaN    NaN   \n",
       "75%        48.000000       NaN      12.000000              NaN    NaN   \n",
       "max        90.000000       NaN      16.000000              NaN    NaN   \n",
       "\n",
       "        hours-per-week  income  \n",
       "count     32561.000000   32561  \n",
       "unique             NaN       2  \n",
       "top                NaN   <=50K  \n",
       "freq               NaN   24720  \n",
       "mean         40.437456     NaN  \n",
       "std          12.347429     NaN  \n",
       "min           1.000000     NaN  \n",
       "25%          40.000000     NaN  \n",
       "50%          40.000000     NaN  \n",
       "75%          45.000000     NaN  \n",
       "max          99.000000     NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2aa40c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2c88dc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAELCAYAAAAybErdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFV5JREFUeJzt3X+0nVV95/H3ByKIMvxOoyRoqMQ6aKfKRGTqGmXEQgA1rhlrUUcig8OsGfw1q+OItmul4482znSk0lVdi0oU1CVStEKLFhHEWbYFCYgoRCUCmgQI0QT8Qf0R+c4fZ9+Zw903JLknyTkx79daZ93n2c/ez/neG+75nL2f51xSVUiSNGyfcRcgSZo8hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM46FdGkhOTrBvD874jyYd29/NKu9KccRcg7UmSnAh8rKoWTLVV1R+PryJp13DmIEnqGA6aeEmOTPKpJBuT3J3kTa39gCQfSbI5yR3Ac6eNqyTHDO1/JMm7h/aXJrk1yQ+TfCfJktZ+VpLVSX6U5K4k/6m1PxH4HHBkkh+3x5FJ/ijJx4bO+7Iktyd5MMn1Sf750LF7kvy3JLcleSjJJ5M8/jG+9632T/K6JF/e2vfcvt8PJPlcq/XvkzwpyZ+1n9k3kzxnFv8k2gsYDppoSfYB/gb4GjAfOAl4S5JTgOXA09rjFGDZDpz3eOAS4K3AIcALgHva4QeAlwAHAWcB5yc5rqp+ApwK3FtVB7bHvdPO+3TgE8BbgLnAZ4G/SbLfULdXAkuAo4F/AbxuG+XuaP/pY/8QOAL4GfCPwC1t/3LgfTtwLu1FDAdNuucCc6vqnVX186q6C/hL4AwGL3zvqapNVbUWuGAHzns2sLKqrqmqR6pqfVV9E6Cqrqqq79TAl4DPA/96O8/7e8BV7by/AP4UOAD47aE+F1TVvVW1iUHwPXsb59zR/sP+uqpurqqfAn8N/LSqLqmqXwKfBJw5aEaGgybdUxks4zw49QDeAcwDjgTWDvX97g6c9yjgOzMdSHJqkhuSbGrPdxqDd9rb48jhOqrqkVbj/KE+9w9tPwwc2J53avnnx0les63+22nD0PY/zbC/I+fSXsS7lTTp1gJ3V9Wi6QeS3M3gRf721vSUaV0eBp4wtP8kYOpW17UMlqOmn3N/4FPAmcAVVfWLJJ8B0rps688Y3wv85tD50mpcv41xVNWp2+ozzU8Y+v6SPGkHx0tb5cxBk+4rwI+SvK1dgN43ybOSPBe4DHh7kkOTLADeOG3srcCr25glwAuHjl0EnJXkpCT7JJmf5BnAfsD+wEZgS5JTgZOHxm0ADk9y8FbqvQw4vZ33ccDvM1jr/4eRfgoz+xrwzCTPbhep/2gXPIf2UoaDJlpbG38Jg3X2u4HvAx8CDgb+B4MlnLsZXBf46LThbwZeCjwIvAb4zNB5v0K72Aw8BHwJeGpV/Qh4E4MX+c3Aq4Erh8Z9k8EF57vaMteR0+r9FvDvgT9vtb4UeGlV/XzEH0Wnqr4NvBP4AnAn8OXHHiFtv/g/+5EkTefMQZLUMRwkSR3DQZLUMRwkSR3DQZLU2WM/BHfEEUfUwoULx12GJO0xbr755u9X1dzt6bvHhsPChQtZtWrVuMuQpD1Gku3+EzMuK0mSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKmzx34ITpp0C8+7atZj71lx+k6sRNpxzhwkSR3DQZLUMRwkSR3DQZLUMRwkSZ1thkOSlUkeSPKNobbDklyT5M729dDWniQXJFmT5LYkxw2NWdb635lk2VD7v0zy9TbmgiTZ2d+kJGnHbM/M4SPAkmlt5wHXVtUi4Nq2D3AqsKg9zgE+CIMwAZYDzwOOB5ZPBUrr8x+Hxk1/LknSbrbNcKiq/wNsmta8FLi4bV8MvHyo/ZIauAE4JMmTgVOAa6pqU1VtBq4BlrRjB1XVDVVVwCVD55IkjclsrznMq6r72vb9wLy2PR9YO9RvXWt7rPZ1M7RLksZo5AvS7R1/7YRatinJOUlWJVm1cePG3fGUkrRXmm04bGhLQrSvD7T29cBRQ/0WtLbHal8wQ/uMqurCqlpcVYvnzt2u/0e2JGkWZhsOVwJTdxwtA64Yaj+z3bV0AvBQW366Gjg5yaHtQvTJwNXt2A+TnNDuUjpz6FySpDHZ5h/eS/IJ4ETgiCTrGNx1tAK4LMnZwHeBV7bunwVOA9YADwNnAVTVpiTvAm5q/d5ZVVMXuf8LgzuiDgA+1x6SpDHaZjhU1au2cuikGfoWcO5WzrMSWDlD+yrgWduqQ5K0+/gJaUlSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSZ6RwSPJfk9ye5BtJPpHk8UmOTnJjkjVJPplkv9Z3/7a/ph1fOHSet7f2byU5ZbRvSZI0qlmHQ5L5wJuAxVX1LGBf4AzgvcD5VXUMsBk4uw05G9jc2s9v/UhybBv3TGAJ8IEk+862LknS6EZdVpoDHJBkDvAE4D7gRcDl7fjFwMvb9tK2Tzt+UpK09kur6mdVdTewBjh+xLokSSOYdThU1XrgT4HvMQiFh4CbgQerakvrtg6Y37bnA2vb2C2t/+HD7TOMeZQk5yRZlWTVxo0bZ1u6JGkbRllWOpTBu/6jgSOBJzJYFtplqurCqlpcVYvnzp27K59KkvZqoywrvRi4u6o2VtUvgE8DzwcOactMAAuA9W17PXAUQDt+MPCD4fYZxkiSxmCUcPgecEKSJ7RrBycBdwBfBF7R+iwDrmjbV7Z92vHrqqpa+xntbqajgUXAV0aoS5I0ojnb7jKzqroxyeXALcAW4KvAhcBVwKVJ3t3aLmpDLgI+mmQNsInBHUpU1e1JLmMQLFuAc6vql7OtS5I0ulmHA0BVLQeWT2u+ixnuNqqqnwK/u5XzvAd4zyi1SJJ2Hj8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM5IH4KTtHssPO+qkcbfs+L0nVSJ9hbOHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJnZHCIckhSS5P8s0kq5P8qySHJbkmyZ3t66Gtb5JckGRNktuSHDd0nmWt/51Jlo36TUmSRjPqzOH9wN9V1TOA3wJWA+cB11bVIuDatg9wKrCoPc4BPgiQ5DBgOfA84Hhg+VSgSJLGY9bhkORg4AXARQBV9fOqehBYClzcul0MvLxtLwUuqYEbgEOSPBk4BbimqjZV1WbgGmDJbOuSJI1ulJnD0cBG4MNJvprkQ0meCMyrqvtan/uBeW17PrB2aPy61ra1dknSmIwSDnOA44APVtVzgJ/w/5eQAKiqAmqE53iUJOckWZVk1caNG3fWaSVJ04wSDuuAdVV1Y9u/nEFYbGjLRbSvD7Tj64GjhsYvaG1ba+9U1YVVtbiqFs+dO3eE0iVJj2XW4VBV9wNrk/xGazoJuAO4Epi642gZcEXbvhI4s921dALwUFt+uho4Ocmh7UL0ya1NkjQmc0Yc/0bg40n2A+4CzmIQOJclORv4LvDK1vezwGnAGuDh1peq2pTkXcBNrd87q2rTiHVJkkYwUjhU1a3A4hkOnTRD3wLO3cp5VgIrR6lFkrTz+AlpSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVJn1A/BSdJOs/C8q2Y99p4Vp+/ESuTMQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUGTkckuyb5KtJ/rbtH53kxiRrknwyyX6tff+2v6YdXzh0jre39m8lOWXUmiRJo9kZM4c3A6uH9t8LnF9VxwCbgbNb+9nA5tZ+futHkmOBM4BnAkuADyTZdyfUJUmapZHCIckC4HTgQ20/wIuAy1uXi4GXt+2lbZ92/KTWfylwaVX9rKruBtYAx49SlyRpNKPOHP4M+O/AI23/cODBqtrS9tcB89v2fGAtQDv+UOv//9pnGPMoSc5JsirJqo0bN45YuiRpa2YdDkleAjxQVTfvxHoeU1VdWFWLq2rx3Llzd9fTStJeZ84IY58PvCzJacDjgYOA9wOHJJnTZgcLgPWt/3rgKGBdkjnAwcAPhtqnDI+RJI3BrGcOVfX2qlpQVQsZXFC+rqpeA3wReEXrtgy4om1f2fZpx6+rqmrtZ7S7mY4GFgFfmW1dkqTRjTJz2Jq3AZcmeTfwVeCi1n4R8NEka4BNDAKFqro9yWXAHcAW4Nyq+uUuqEuStJ12SjhU1fXA9W37Lma426iqfgr87lbGvwd4z86oRZI0Oj8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM6swyHJUUm+mOSOJLcneXNrPyzJNUnubF8Pbe1JckGSNUluS3Lc0LmWtf53Jlk2+rclSRrFKDOHLcDvV9WxwAnAuUmOBc4Drq2qRcC1bR/gVGBRe5wDfBAGYQIsB54HHA8snwoUSdJ4zDocquq+qrqlbf8IWA3MB5YCF7duFwMvb9tLgUtq4AbgkCRPBk4BrqmqTVW1GbgGWDLbuiRJo9sp1xySLASeA9wIzKuq+9qh+4F5bXs+sHZo2LrWtrV2SdKYjBwOSQ4EPgW8pap+OHysqgqoUZ9j6LnOSbIqyaqNGzfurNNKkqYZKRySPI5BMHy8qj7dmje05SLa1wda+3rgqKHhC1rb1to7VXVhVS2uqsVz584dpXRJ0mMY5W6lABcBq6vqfUOHrgSm7jhaBlwx1H5mu2vpBOChtvx0NXBykkPbheiTW5skaUzmjDD2+cBrga8nubW1vQNYAVyW5Gzgu8Ar27HPAqcBa4CHgbMAqmpTkncBN7V+76yqTSPUJUka0azDoaq+DGQrh0+aoX8B527lXCuBlbOtRZK0c40yc5CkibXwvKtGGn/PitN3UiV7Jv98hiSpYzhIkjqGgySpYzhIkjqGgySpYzhIkjreyirtZbzFU9vDmYMkqWM4SJI6hoMkqeM1B+3RXD+Xdg1nDpKkjjMHSSMZZfbmzG1yOXOQJHUMB0lSx2Ul7XZeRJYmnzMHSVLHcJAkdQwHSVLHcJAkdbwg/SvM+88lzZYzB0lSx5mDJG3D3nj7teGg7eISlbR3cVlJktRx5iANcYak3WFP+O/McJgge+O6pqTJ5LKSJKljOEiSOoaDJKkzMdcckiwB3g/sC3yoqlaMuaTtsidcWJKkHTURM4ck+wJ/AZwKHAu8Ksmx461KkvZekzJzOB5YU1V3ASS5FFgK3LErnsx3+5L02FJV466BJK8AllTV69v+a4HnVdUbpvU7Bzin7f4G8K22fQTw/d1U7o6a1NomtS6Y3NomtS6Y3NomtS6Y3Np2ZV1Praq529NxUmYO26WqLgQunN6eZFVVLR5DSds0qbVNal0wubVNal0wubVNal0wubVNSl0Tcc0BWA8cNbS/oLVJksZgUsLhJmBRkqOT7AecAVw55pokaa81EctKVbUlyRuAqxncyrqyqm7fgVN0S00TZFJrm9S6YHJrm9S6YHJrm9S6YHJrm4i6JuKCtCRpskzKspIkaYIYDpKkjuEgSepMxAXpHZXkGQw+QT2/Na0Hrqyq1eOraqDVNh+4sap+PNS+pKr+bnyVPVqSS6rqzAmo43nA6qr6YZIDgPOA4xh8Ov6Pq+qhMdU1ddfcvVX1hSSvBn4bWA1cWFW/GEdd0u6yx12QTvI24FXApcC61ryAwS/ypeP8g31J3gScy+AF5NnAm6vqinbslqo6bkx1Tb8tOMC/Aa4DqKqX7faipgpJbgd+q92xdiHwMHA5cFJr/7djquvjDN48PQF4EDgQ+HSrK1W1bBx1aedJ8mtV9cC465hJksOr6gdjLaKq9qgH8G3gcTO07wfcOebavg4c2LYXAqsYBATAV8dY1y3Ax4ATgRe2r/e17ReO+We2erjOacduHWNdt7Wvc4ANwL5tP1PHxljbwcAK4JvAJuAHDN6QrAAOGXNtBwF/AnwUePW0Yx8YY12HTXscDtwDHAocNuaf2QrgiLa9GLgLWAN8d5y/n3viNYdHgCNnaH9yOzZO+1RbSqqqexi8CJ+a5H0MXlTGZTFwM/AHwENVdT3wT1X1par60hjrAvhGkrPa9teSLAZI8nRgnEs3+7SlpX/GYPZwcGvfH3jc2KoauAzYDJxYVYdV1eEMZoKb27Fx+jCD/9Y/BZyR5FNJ9m/HThhfWXyfwe/A1GMVg+XfW9r2OJ1eVVN/S+l/Ab9XVccAvwP873EVtSdec3gLcG2SO4G1re0pwDHAG7Y6avfYkOTZVXUrQFX9OMlLgJXAb46rqKp6BDg/yV+1rxuYnH/71wPvT/KHDH6B/zHJWgb/tq8fY10XMXhnvi+DUP2rJHcxeIG7dIx1ASysqvcON1TV/cB7k/yHMdU05WlV9e/a9meS/AFwXZKxLV02b2XwYvvWqvo6QJK7q+ro8ZYFwJwkc6pqC3BAVd0EUFXfHgrW3W6Pu+YAkGQfBn/me/iC9E1V9cvxVQVJFgBb2i/q9GPPr6q/H0NZnSSnA8+vqneMu5YpSQ4CjmYQWuuqasOYSyLJkQBVdW+SQ4AXA9+rqq+Mua7PA18ALp76OSWZB7wO+J2qevEYa1sNPLO9IZlqex2DF+cDq+qpY6xtAXA+gzcey4GvVdWvj6ueKUneCLyUwfLSCxgsdX0aeBHw61X12rHUtSeGg7Q3S3Iog7u6lgK/1po3MPh7ZCuqavMYa/ufwOer6gvT2pcAf15Vi8ZT2aNqeRnwDgYzsCeNux6AJCcC/xl4OoM3SGuBzzD4U0JbxlKT4SD96khyVlV9eNx1zGSSamu3TT+tqr4xSXVNN87aDAfpV0iS71XVU8Zdx0wmtbZJrQvGW9ukXJSUtJ2S3La1Q8C83VlLV8CE1japdcHk1mY4SHueecApDG5dHRbgH3Z/OY8yqbVNal0wobUZDtKe528Z3Plz6/QDSa7f/eU8yqTWNql1wYTW5jUHSVJnT/yEtCRpFzMcJEkdw0GS1DEcJEkdw0GS1Pm/BSVDLMcR+xMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2c88c5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2adcd0668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2a9bc7c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2a9e09d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2a9de1eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, col in enumerate(data.drop(\"hours-per-week\", axis = 1)):\n",
    "    d = data[col].value_counts().sort_index()\n",
    "    plt.bar(d.index, d)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "plt.hist(data['hours-per-week'], bins = 20);\n",
    "plt.title(\"Hours Per Week\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Preprocessing\n",
    "The following cells  demonstrates the functions used in preprocessing, concluding with the division of data into a training and testing sets, that are then preprocessed.  \n",
    "\n",
    "##### Dummy Variables\n",
    "\n",
    "In the creation of dummy variables, the most frequently occuring class will be dropped as a way of avoiding multicollinearity.  \n",
    "\n",
    "Thus, for **`n`** categories, **`n-1`** features will be created. Below demonstrates finding the most frequent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Value Counts:\n",
      " Private             22696\n",
      " Self-emp-not-inc     2541\n",
      " Local-gov            2093\n",
      " ?                    1836\n",
      " State-gov            1298\n",
      " Self-emp-inc         1116\n",
      " Federal-gov           960\n",
      " Without-pay            14\n",
      " Never-worked            7\n",
      "Name: workclass, dtype: int64\n",
      "\n",
      "Top category: 22696\n"
     ]
    }
   ],
   "source": [
    "val_count = data['workclass'].value_counts()\n",
    "print('All Value Counts:')\n",
    "print(val_count)\n",
    "\n",
    "top = val_count[0]\n",
    "print(\"\\nTop category:\", top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot Encoder  \n",
    "\n",
    "Dummies will be created using `sklearn`'s `OneHotEncoder`.  The following cell demonstrates fitting and transforming data using the One Hot Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "    beg end\n",
      "500   b   z\n",
      "501   a   y\n",
      "502   c   y\n",
      "503   a   y\n",
      "504   c   z\n",
      "\n",
      "Test df\n",
      "   beg end\n",
      "56   c   y\n",
      "72   b   y\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ex_df = pd.DataFrame(\n",
    "    np.array([['b', 'a', 'c', 'a', 'c',], [\"z\",\"y\",\"y\",\"y\",\"z\"]]).T,\n",
    "    columns = [\"beg\",\"end\"],\n",
    "    index = range(500,505))\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    np.array([[\"c\",\"b\"],[\"y\",\"y\"]]).T,\n",
    "    columns = [\"beg\",\"end\"],\n",
    "    index = [56,72])\n",
    "\n",
    "print(\"Initial DataFrame:\")\n",
    "print(ex_df)\n",
    "\n",
    "print(\"\\nTest df\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed values\n",
      "[[0. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 1.]]\n",
      "\n",
      "Categories\n",
      "[array(['a', 'b', 'c'], dtype=object), array(['y', 'z'], dtype=object)]\n",
      "\n",
      "Final DataFrame\n",
      "     a    b    c    y    z\n",
      "0  0.0  1.0  0.0  0.0  1.0\n",
      "1  1.0  0.0  0.0  1.0  0.0\n",
      "2  0.0  0.0  1.0  1.0  0.0\n",
      "3  1.0  0.0  0.0  1.0  0.0\n",
      "4  0.0  0.0  1.0  0.0  1.0\n",
      "\n",
      "Transformed test df\n",
      "     a    b    c    y    z\n",
      "0  0.0  0.0  1.0  1.0  0.0\n",
      "1  0.0  1.0  0.0  1.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate OneHotEncoder\n",
    "# sparse = False means data will not be stored in sparse matrix\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "\n",
    "# Fitting OHE with the \"training\" data\n",
    "ohe.fit(ex_df)\n",
    "\n",
    "# Transforming the \"training\" dat\n",
    "tr_vals = ohe.transform(ex_df)\n",
    "\n",
    "print(\"\\nTransformed values\")\n",
    "print(tr_vals)\n",
    "\n",
    "print(\"\\nCategories\")\n",
    "print(ohe.categories_)\n",
    "\n",
    "# Creating column names from `.categories_`\n",
    "ohe_cats = np.concatenate(ohe.categories_)\n",
    "\n",
    "# In creation of new df. Note the use of np.concatenate\n",
    "final_df = pd.DataFrame(tr_vals, columns = ohe_cats)\n",
    "\n",
    "print(\"\\nFinal DataFrame\")\n",
    "print(final_df)\n",
    "\n",
    "# Putting everything together to transform test data\n",
    "print(\"\\nTransformed test df\")\n",
    "print(pd.DataFrame(ohe.transform(test_df), columns= ohe_cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "##### LabelEncoder\n",
    "\n",
    "`sklearn`'s `LabelEncoder` will be used to transform our income variable from strings to 0s and 1s.  \n",
    "\n",
    "Demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Train Series\n",
      "0     <=50K\n",
      "1      >50K\n",
      "2     <=50K\n",
      "3      >50K\n",
      "4     <=50K\n",
      "5     <=50K\n",
      "6      >50K\n",
      "7     <=50K\n",
      "8      >50K\n",
      "9     <=50K\n",
      "dtype: object\n",
      "\n",
      "Target Test Series\n",
      "0     <=50K\n",
      "1      >50K\n",
      "2      >50K\n",
      "3      >50K\n",
      "4      >50K\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create target Series\n",
    "target_train = pd.Series(np.random.choice(data['income'].unique(), size = 10))\n",
    "target_test = pd.Series(np.random.choice(data['income'].unique(), size = 5))\n",
    "print(\"Target Train Series\")\n",
    "print(target_train)\n",
    "\n",
    "print(\"\\nTarget Test Series\")\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed training values\n",
      "[0 1 0 1 0 0 1 0 1 0]\n",
      "\n",
      "Transformed test values\n",
      "[0 1 1 1 1]\n",
      "\n",
      "LabelEncoder `.classes_`\n",
      "[' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit with training data\n",
    "le.fit(target_train)\n",
    "\n",
    "# Transform training and test data\n",
    "trans_train = le.transform(target_train)\n",
    "trans_test = le.transform(target_test)\n",
    "\n",
    "print(\"Transformed training values\")\n",
    "print(trans_train)\n",
    "\n",
    "print(\"\\nTransformed test values\")\n",
    "print(trans_test)\n",
    "\n",
    "print(\"\\nLabelEncoder `.classes_`\")\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "##### Define a custom preprocessing function\n",
    "Using the processes demonstrated above, a function is created to preprocess the census data.  \n",
    "\n",
    "The function is then used to create a training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_census(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    ### Hardcode variables which need categorical encoding\n",
    "    to_encode = [\"workclass\", \"occupation\", \"sex\"]\n",
    "\n",
    "    ### Find top categories in categorical columns\n",
    "    ### Used for dropping majority class to prevent multi-colinearity\n",
    "    top_categories = []\n",
    "\n",
    "    for col in to_encode:\n",
    "        top_categories.append(X_train[col].value_counts().index[0])\n",
    "\n",
    "    ### Create and fit one-hot encoder for categoricals\n",
    "    OHE = OneHotEncoder(sparse = False)\n",
    "    OHE.fit(X_train[to_encode])\n",
    "\n",
    "    ## Create and fit Label encoder for target\n",
    "    LabEnc = LabelEncoder()\n",
    "    LabEnc.fit(y_train)\n",
    "\n",
    "    def create_encoded_df(X, to_encode = to_encode, OHE = OHE, top_categories = top_categories):\n",
    "        # Return columns which need encoding.\n",
    "        def return_encoded_cols(X, to_encode = to_encode, OHE = OHE, top_categories = top_categories):\n",
    "            # Use onehotencoder to transform.\n",
    "            # Use \"categories\" to name\n",
    "            toRet = pd.DataFrame(OHE.transform(X[to_encode]), columns = np.concatenate(OHE.categories_))\n",
    "\n",
    "            # Drop top_categories and return\n",
    "            return toRet.drop(top_categories, axis = 1)\n",
    "\n",
    "        # create encoded columns\n",
    "        ret_cols = return_encoded_cols(X)\n",
    "\n",
    "        # Drop columns that were encoded\n",
    "        dr_enc = X.drop(to_encode, axis = 1)\n",
    "\n",
    "        # Concatenate values\n",
    "        # use index from original data\n",
    "        # use combined column names\n",
    "        return pd.DataFrame(np.concatenate([ret_cols.values, dr_enc.values],axis = 1),\n",
    "                            index = dr_enc.index,\n",
    "                            columns = list(ret_cols.columns) + list(dr_enc.columns))\n",
    "\n",
    "\n",
    "    def encode_target(y, LabEnc = LabEnc):\n",
    "        # Use label encoder, and supply with original index\n",
    "        return pd.Series(LabEnc.transform(y), index= y.index)\n",
    "\n",
    "    return create_encoded_df(X_train), create_encoded_df(X_test), encode_target(y_train), encode_target(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and testing sets; preprocess them.\n",
    "target = data['income']\n",
    "predictors = data.drop(\"income\", axis = 'columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_census(*train_test_split(predictors, target, test_size = .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Fitting Models to Data  \n",
    "\n",
    "If the above functions are defined correctly, the following cells should work; creating predictions from your adaptive-boosted model.\n",
    "\n",
    "Try playing around with the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6fabc50cb14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_adaboost_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-8d8b1bb9728a>\u001b[0m in \u001b[0;36msimple_adaboost_fit\u001b[0;34m(X, y, n_estimators)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Create bootstrap sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mbs_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboot_strap_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-5a9c803644c1>\u001b[0m in \u001b[0;36mboot_strap_selection\u001b[0;34m(X, y, weights)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Take random sample of indicies, with replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbss_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Subset arrays with indicies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "d = simple_adaboost_fit(X_train.values.copy(), y_train.values.copy(), 50)\n",
    "preds = predict_T(X_test, d)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This image gives an idea of how the precision and recall on both the training and test set changes as the number of estimators is changed.  \n",
    "\n",
    "![predictor](./assets/PreRedEst.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"sklearn\"></a>\n",
    "### `sklearn` Implementation of Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4968\n",
      "           1       0.59      0.50      0.54      1545\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      6513\n",
      "   macro avg       0.72      0.69      0.70      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89      4968\n",
      "           1       0.67      0.49      0.57      1545\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6513\n",
      "   macro avg       0.76      0.71      0.73      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators = 50)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest:\\n\")\n",
    "print(classification_report(y_test, RF.predict(X_test)))\n",
    "ABC = AdaBoostClassifier(n_estimators = 50)\n",
    "ABC.fit(X_train, y_train)\n",
    "print(\"\\nAdaBoost:\\n\")\n",
    "print(classification_report(y_test, ABC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You should find that the precision and recall of the your custom Adaptive Boosting are very similar to the `sklearn` adaboost.\n",
    "\n",
    "Notice the higher precision of the AdaBoost compared to the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
