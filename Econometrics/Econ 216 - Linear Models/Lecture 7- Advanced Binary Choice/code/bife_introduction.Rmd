---
title: "bife - Binary Choice Models with Fixed Effects"
author: "Daniel Czarnowske, Florian Heiss, Amrei Stammann"
date: "`r Sys.Date()`"
bibliography: refs.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{bife - Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

In econometrics, fixed effects binary choice models are important tools for panel data analysis. The package `bife` provides a new approach suggested by @sta16 to estimate logit and probit panel data models of the following form:

$$y_{it} = \mathbf{1}\left[\mathbf{x}_{it}\boldsymbol{\beta} + \alpha_{i} + \epsilon_{it} > 0\right] \;,$$

where $i = 1, \dots, N$ and $t = 1, \dots, T_i$ denote different indices. In many applications, $i$ represents individuals, firms or other cross-sectional units and $t$ represents time in a longitudinal data set. But the setup is also useful for instance if $i$ represents ZIP code areas and $t$ is an index of individuals. The dependent variable $y_{it}$ is binary. We observe regressors collected in the vector $\mathbf{x}_{it}$ but we don't observe the error term $\epsilon_{it}$. 

We are primarily interested in estimating the parameters $\boldsymbol{\beta}$, but the model also includes individual fixed effects $\alpha_{i}$. We assume $E(\epsilon_{it} | \mathbf{X}_{i}, \alpha_{i}) = 0$ but don't make any assumptions about the marginal distribution of $\alpha_{i}$ or its correlation with the regressors $\mathbf{x}_{i1},\dots, \mathbf{x}_{iT_i}$.

The estimator implemented in this package is based on maximum likelihood estimation (ML) of both $\boldsymbol{\beta}$ and $\alpha_1, \dots, \alpha_N$. It actually is the same estimator as a logistic regression a set of individual dummy variables  such as 
```{r, eval=FALSE}
glm(y ~ X + factor(i), family = binomial())
```
The main difference is that In contrast to `glm()`, `bife()` applies a pseudo-demeaning algorithm proposed by @sta16^[The proposed pseudo-demeaning algorithm is in spirit of @gre04 and @cha80.]. Its computational costs are lower by orders of magnitude if $N$ is reasonably large. 

It is well known that as $N\rightarrow\infty$, the ML estimator is not consistent. This "incidental parameters problem" can be severe if $T$ is small.
To tackle this problem, we provide an analytical and a jackknife bias correction for the structural parameters $\boldsymbol{\beta}$ and the average partial effects [@han04].
Thus this package is well suited to analyse big micro-data where $N$ and/or $T$ are large.

This package provides methods to:

* `bife()` -- estimate binary choice models with fixed effects with/-out bias correction
* `apeff_bife()` -- compute average partial effects^[Partial effects are also called marginal effects.] with/-out bias correction

Both methods utilize the `RcppArmadillo`-package provided by @edd14.


An alternative to full ML estimation of all parameters is a conditional maximum likelihood estimator which conditions out $\alpha_1, \dots, \alpha_N$ and only estimates $\boldsymbol\beta$. It is for example available  with `survival::clogit()` and is consistent under the usual regularity conditions. The problem with this estimator is that its computational burden increases dramatically for larger $T$ values and that partial effects cannot be consistently estimated since this would require estimates of $\alpha_1, \dots, \alpha_N$.


## Computational Advantage^[A more detailed analyses can be found in @sta16]

To demonstrate the computational advantage of `bife()`, we compare it with two popular methods to estimate logit models with fixed effects: `glm()` and `survival::clogit()`.^[We use the `base`-package version 3.3.1 for all analyses with `glm()` and the survival-package version 2.39-5 for all analyses with `survival::clogit()`.] To compare these methods, we utilize the data generating process of @gre04 :

$$y_{it} = \mathbf{1}\left[w_{it} + \epsilon_{it} > 0\right] \;,$$
$$w_{it} = \alpha_{i} + x_{it} + d_{it} \;,$$
$$\alpha_{i} = \sqrt{T} \bar{x_{i}} + a_{i} \;,$$
$$x_{it} \sim \mathcal{N}[0, 1] \;,$$
$$d_{it} = \mathbf{1}\left[x_{it} + h_{it} > 0\right] \;,$$
$$\epsilon_{it} = \log\left[u_{it} / (1 - u_{it})\right] \;,$$

where $x_{it}, h_{it}, a_{i} \sim \mathcal{N}[0, 1]$, $u_{it} \sim \mathcal{U}[0, 1]$, $i = 1, \dots, N$, and $t = 1, \dots, T$.

To show how the computational burden changes with $N$ and $T$, we either fix $N$ and vary $T$ or vice versa. For each of the different combinations we generate 50 datasets and measure the compuational time with the following commands:

```{r, eval=FALSE}
time_bife   <- system.time(bife(y ~ x + d | id, model = "logit", bias_corr = "ana"))[3]
time_clogit <- if(require("survival")) system.time(clogit(y ~ x + d + strata(id)))[3]
time_glm    <- system.time(glm(y ~ x + d + 0 + factor(id), family = binomial()))[3]
```

The following table reports the average computation time in seconds for each method and all combinations of $N$ and $T$. Note that `bife_corr` refers to the results with analytical bias correction.

```{r, echo=FALSE, results='asis'}
# Load 'bife'
library("bife")

# Load results --- store_N and store_T
time_n <- time_n
time_t <- time_t

# N and T vector
N_vector <- rep(100, 10)
T_vector <- rep(10, 10)

# Bind results
results <- cbind("N" = time_n[, 1], "T" = T_vector, time_n[, 2:4], "N" = N_vector, time_t)

# Print results
knitr::kable(results)
```

Visualizing the results illustrates that the computational time of `bife()` is linear in both dimensions and hence is well suited to analyse big panel data. The left figure depicts that with $T=10$, `glm()` becomes dramatically more computationally intensive as  $N$ increases. Besides, `glm()` is  always more time consuming than the other two methods regardless which dimension is varied. Additionally, the right figure already indicates that the computation time of `survival::clogit()` increases more than linearly with $T$. In applications with very large $T$,  `survival::clogit()` can quickly become computationally infeasible in terms of convergence, computation time or technique.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show='hold'}
# Load package
if (require("ggplot2")) {

  # Colour palette for colour-blind
  cb.Palette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
  
  # Transform to data.frame
  time_n <- data.frame(time_n)
  time_t <- data.frame(time_t)
  
  # Regression N
  plot_N <- data.frame(N = time_n[["N"]])
  plot_N[["bife_corr"]] <- fitted(lm(bife_corr ~ N, data = time_n))
  plot_N[["clogit"]] <- fitted(lm(clogit ~ N, data = time_n))
  plot_N[["glm"]] <-
  fitted(lm(glm ~ N + I(N ^ 2) + I(N ^ 3), data = time_n))
  
  # Regression T
  plot_T <- data.frame(T = time_t[["T"]])
  plot_T[["bife_corr"]] <- fitted(lm(bife_corr ~ T, data = time_t))
  plot_T[["clogit"]] <-
  fitted(lm(clogit ~ T + I(T ^ 2) + I(T ^ 3), data = time_t))
  plot_T[["glm"]] <- fitted(lm(glm ~ T, data = time_t))
  
  # Plot N
  p <- ggplot(plot_N) +
  ylab(NULL) +
  xlim(100, 1000) +
  ylim(0, 1) +
  theme_bw() +
  theme(legend.justification = c(1, 1),
  legend.position = c(1, 1)) +
  geom_line(aes(N, bife_corr, colour = "bife_corr"), size = 0.5) +
  geom_line(aes(N, clogit, colour = "clogit"), size = 0.5) +
  geom_line(aes(N, glm, colour = "glm"), size = 0.5) +
  scale_color_manual("", values = cb.Palette)
  
  # Plot T
  q <- ggplot(plot_T) +
  ylab(NULL) +
  xlim(10, 100) +
  ylim(0, 1) +
  theme_bw() +
  theme(legend.justification = c(0, 1),
  legend.position = c(0, 1)) +
  geom_line(aes(T, bife_corr, colour = "bife_corr"), size = 0.5) +
  geom_line(aes(T, clogit, colour = "clogit"), size = 0.5) +
  geom_line(aes(T, glm, colour = "glm"), size = 0.5) +
  scale_color_manual("", values = cb.Palette)
  
  # Print
  p
  q
}
```

## Workflow

This section demonstrates two examples of a typical workflow using `bife::` with real datasets. The first example
uses a balanced panel with many fixed effects (large $N$) and the second example a unbalanced panel with large $T_i$.


### Example: @hys99 --- Large $N$

The first example is inspired by @hys99 who analysed the labor force participation of married women in a "classic" balanced panel. The sample was obtained from the "Panel Study of Income Dynamics" and contains information about $N=1461$ women that were observed over $T=9$ years.

To analyse the labor force participation of married women, we specify the following model:

$$LFP_{it} = \mathbf{1}\left[\beta_{1} AGE_{it} + \beta_{2} (INCH / 1000)_{it} + \beta_{3} KID1_{it} 
  + \beta_{4} KID2_{it} + \beta_{5} KID3_{it} +  \alpha_{i} + \epsilon_{it} > 0\right] \;,$$
  
where $LFP_{it}$ indicates the labor force participation of a married woman, $AGE_{it}$ refers to the age, $(INCH / 1000)_{it}$ is the husbands income in thousand dollars, and the $KID*_{it}$ variables refer to the number of kids in a certain age group.

We start with a comparison of different methods to estimate logit models with fixed effects similiar to the section before. The following table reports the structural parameters ($\boldsymbol{\beta}$) and the execution time for each method, where **bife.corr** refers to the results with analytical bias correction.

```{r, echo=FALSE, results='asis'}
# Load results
results_psid <- results_psid

# Change the order of the cols and rename cols
results_psid <- cbind(results_psid[, 1], results_psid[, 3], results_psid[, 2], results_psid[, 4])
colnames(results_psid) <- c("bife",  "glm", "bife_corr", "clogit")

# Print results
knitr::kable(results_psid)
```

There are two things to highlight in this table. First `bife(..., bias_corr = "no")` and `glm(..., family = binomial())` deliver the same structural parameter estimates, but the execution time of `glm(..., family = binomial())` is about 10,000 times as long. Second the small $T$ leads to incidental parameters bias, but the analytical bias correction (`bife(..., bias_corr = "ana")`) is able to correct the structural parameters such that we get very competitive results compared to the unbiased alternative `survival::clogit()`.

Next, we show how to estimate the specification above with `bife()`.

```{r, echo=FALSE, warning=FALSE}
# Load data
psid <- psid
```

```{r}
mod_logit <- bife(LFP ~ AGE + I(INCH / 1000) + KID1 + KID2 + KID3 | ID, data = psid, bias_corr = "ana")
summary(mod_logit)
```

The parameters of binary outcome variables are difficult to interpret quantitatively. In econometrics, partial effects $\frac{\partial Pr(y_{it}=1)}{\partial x_{itj}}$ are of more interest. Neither `glm()` nor `survival::clogit()` provide a routine to compute partial effects. This package provides the function `apeff_bife()` to compute average partial effects based on the estimated model provided by `bife()`. The user simply has to specify which of the variables are discrete and which type of bias correction should be used for the computation of the avarage partial effects. The left column named `apeff` refers to usual uncorrected average partial effects and the right column named `apeff` refers to semi-corrected average partial effects following @sta16.  

```{r}
apeff_bife(mod_logit, discrete = c("KID1", "KID2", "KID3"), bias_corr = "ana")
```

`bife()` also offers the opportunity to estimate fixed effects probit models by specifiying `model = "probit"`.

```{r}
mod_probit <- bife(LFP ~ AGE + I(INCH / 1000) + KID1 + KID2 + KID3 | ID, 
                   data = psid, bias_corr = "ana", model = "probit")
summary(mod_probit)
```

Although the structural parameters are different compared to the logit model due to a different normalization, the average partial effects are similiar:

```{r}
apeff_bife(mod_probit, discrete = c("KID1", "KID2", "KID3"), bias_corr = "ana")
```


### Example: ACS PUMS 2014 --- Large T

The second example is based on a sample drawn from the American Community Survey (ACS PUMS 2014) were the panel structure is slightly different in comparison to the "classic" structure used in the section before. 
Instead of individual fixed effects we consider state fixed effects. $N$ can be now considered as the number of groups (states) and $T_i$ as the group size of group $i$. 

In this example we observe a total of 662,775 married women in $N = 51$ states. Since each state is of different population size, we end up with a highly unbalanced panel were the largest state consists of $T_{\max} = 74,752$  and the smallest of $T_{\min} = 855$ married women.

The model can be described as follows:
$$LFP_{it} = \mathbf{1}\left[\beta_{1} AGEP_{it} + \beta_{2} (PINCP / 1000)_{it} + \beta_{3} FER_{it} + \alpha_{i} + \epsilon_{it} > 0\right] \;,$$
  
where $LFP_{it}$ indicates the labor force participation of a married woman, $AGEP_{it}$ refers to the age, $(PINCP / 1000)_{it}$ is the total persons income in thousand dollars, and $FER_{it}$ indicates if a woman gave birth to a child within the past 12 months. In this example $i$ refers to one of the states and $t$ refers to one of the individuals observed in this state.

As before, we start with a comparison of different methods to estimate logit models with fixed effects.

```{r, echo=FALSE, results='asis'}
# Load results
results_acs <- results_acs

# Change the order of the cols and rename cols
results_acs <- cbind(results_acs[, 1], results_acs[, 3], results_acs[, 2], results_acs[, 4])
colnames(results_acs) <- c("bife",  "glm", "bife_corr", "clogit")

# Print results
knitr::kable(results_acs)
```

There are again two things to highlight. First since the bias of $\boldsymbol{\hat{\beta}}$ obtained from `bife(..., bias_corr = "no")` vanishes with large $T$, the bias correction is redundant. Second since the panel structure consists of very large $T$, `survival::clogit()` is not able to handle this dataset:

```{r}
# Load data
acs <- acs

print(try(if(require("survival")) clogit(LFP ~ AGEP + I(PINCP / 1000) + FER + strata(ST), data = acs)))
```

Next, we will show how to analyse panel data with `bife(..., bias_corr = "no")` following the specification above.

```{r}
mod_logit <- bife(LFP ~ AGEP + I(PINCP / 1000) + FER | ST, data = acs, bias_corr = "no")
summary(mod_logit)
```

```{r}
apeff_bife(mod_logit, discrete = "FER")
```

Since we estimated a logit model without bias-correction, `apeff_bife()` delivers only one column with uncorrected average partial effects.

##Notes

For further details on when to use the bias-corrections for structural parameters and average partial effects please consult @sta16 and @han04. 

## References
