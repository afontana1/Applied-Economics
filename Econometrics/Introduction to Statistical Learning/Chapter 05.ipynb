{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistical Learning \n",
    "Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani is considered a canonical text in the field of statistical/machine learning and is an absolutely fantastic way to move forward in your analytics career. [The text is free to download](http://www-bcf.usc.edu/~gareth/ISL/) and an [online course by the authors themselves](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about) is currently available in self-pace mode, meaning you can complete it any time. Make sure to **[REGISTER FOR THE STANDFORD COURSE!](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)** The videos have also been [archived here on youtube](http://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAdvertising.csv\u001b[m\u001b[m caravan.csv     hitters.csv     khan_ytrain.csv smarket.csv\r\n",
      "Credit.csv      carseats.csv    khan_xtest.csv  nci60_data.csv  usarrests.csv\r\n",
      "auto.csv        college.csv     khan_xtrain.csv nci60_labs.csv  \u001b[31mwage.csv\u001b[m\u001b[m\r\n",
      "boston.csv      default.csv     khan_ytest.csv  portfolio.csv   weekly.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Resampling Methods\n",
    "Covers resampling data through bootstraping and cross validation. Cross validation gets us an error estimate for our test data and boostraping provides estimates for parameter accuracy.\n",
    "\n",
    "### Cross Validation\n",
    "Usually a test set is not available so a simple strategy to create one is to split the available data into training and testing (validation set). For quantitative responses usually use MSE, for categorical can use error rate, area under the curve, F1 score, weighting of confusion matrix, etc...\n",
    "\n",
    "### Leave One Out Cross Validation\n",
    "LOOCV has only one observation in the test set and uses all other n-1 observations to build a model. n different models are built leaving out each observation once and error is averaged over these n trials.  LOOCV is better than simple method above. Model is built on nearly all the data and there is no randomness in the splits since each observation will be left out once. It is computationally expensive especially with large n and a complex model.\n",
    "\n",
    "### k-fold cross validation\n",
    "Similar to LOOCV but this time you leave some number greater than 1 out. Here, k is the number of partitions of your sample, so if you have 1000 observations and k = 10, the each fold will be 100. These 100 observations would act as your test set. Get an MSE for each fold of these 100 observations and take the average. LOOCV is a special case of k-fold CV whenever k equals the number of observations.\n",
    "\n",
    "### bias-variance tradeoff between LOOCV and k-folds\n",
    "Since LOOCV trains on nearly all the data, the test error rate will generally be lower than k-fold and there for less biased. LOOCV will have higher variance since all n models will be very highly correlated to one another. Since the models won't differ much, the test error rate (which what CV is measuring) will vary more than k-fold which has fewer models that are less correlated with one another. A value of k between 5 and 10 is a good rule of thumb that balances the trade-off between bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can do example where LOOCV has higher variance than k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Minimize $$Var(\\alpha X + (1 - \\alpha)Y)$$\n",
    "\n",
    "Properties of variance and covariance\n",
    "$$=Var(\\alpha X) + Var((1 - \\alpha)Y) + 2Cov(\\alpha X, (1 - \\alpha)Y)$$\n",
    "$$=\\alpha^2Var(X) + (1 - \\alpha)^2Var(Y) + 2(\\alpha)(1 - \\alpha)(Cov(X, Y)$$\n",
    "\n",
    "Take derivative and set to 0\n",
    "$$2\\alpha Var(X) - 2(1 - \\alpha)Var(Y) + (2 - 4\\alpha)Cov(X, Y) = 0$$\n",
    "Collect terms\n",
    "$$2\\alpha Var(X) + 2 \\alpha Var(Y) - 4\\alpha Cov(X, Y) = 2Var(Y) - 2Cov(X, Y)$$\n",
    "Solve for $\\alpha$\n",
    "$$\\alpha = \\frac{Var(Y) - Cov(X, Y)}{Var(X) + Var(Y) - 2Cov(X, Y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "a) $\\frac{n-1}{n}$  \n",
    "b) $\\frac{n-1}{n}$  \n",
    "c) Since bootstrapping is sampling with replace, the probability of being any jth obsevation is $\\frac{1}{n}$. The probability of not being the jth observation is $1 - \\frac{1}{n}$. Since each draw is independent we can just multiply the probabilities together to get the probability that the jth observation is not in the sample at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3276800000000001,\n",
       " 0.3660323412732292,\n",
       " 0.36786104643297046,\n",
       " 0.3678776017682465]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 c-f\n",
    "[(1 - 1/n) **n for n in [5, 100, 10000, 100000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 100001)\n",
    "y = (1 - 1/x) ** x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x880b898>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2bWRBz6ZmZNxKFvZtZE/j/W7KNr5UA+VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x87b2550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63239999999999996"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2h\n",
    "# make 10,000 samples of 100 elements each sample from integers 1 - 100\n",
    "# check if 4 is each sample. Take mean.\n",
    "# Looks like very close to theoretical probability\n",
    "data = np.random.randint(1, 101, (100, 10000))\n",
    "np.any(data == 4, axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "a) K-fold CV works by taking the dataset given and randomly splitting it into k non-overlapping datasets. You can shuffle the data first and then just split at regular intervals. Train K models. For each model, use the kth region as the validation set and build on the other k-1 sets. Take the mean of the k errors found to estimate the true test error.  \n",
    "\n",
    "b i) Advantage to validation set is that there are more test sets to validate on which should reduce the bias of what the overall error actually is. Variance should also decrease as the validation set approach is just one split of the data and that split could not represent the test data well. Disadvantage is training more models.  \n",
    "\n",
    "b ii) Advantage to LOOCV is a decrease in variance as the k models are not as highly correlated as the each LOOCV model is. Also, K-folds is computationally less expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "* Using the bootstrap, create many (say 10,000) samples of your data.\n",
    "* Create each sample by drawing n times (where n is number of observations in your original) with replacement.\n",
    "* Build your model for each sample and calculate the mean and standard deviation of estimated parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv('data/default.csv')\n",
    "default['student_yes'] = (default['student'] == 'Yes').astype('int')\n",
    "default['default_yes'] = (default['default'] == 'Yes').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_yes</th>\n",
       "      <th>default_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income  student_yes  default_yes\n",
       "0      No      No   729.526495  44361.625074            0            0\n",
       "1      No     Yes   817.180407  12106.134700            1            0\n",
       "2      No      No  1073.549164  31767.138947            0            0\n",
       "3      No      No   529.250605  35704.493935            0            0\n",
       "4      No      No   785.655883  38463.495879            0            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = default[['balance', 'income']]\n",
    "y = default['default_yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-11.52731503]), array([[  5.64078217e-03,   2.07265906e-05]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how tol must be changed to less than default value or convergence won't happen\n",
    "# Use a high value of C to remove regularization\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "model.fit(X, y)\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "Coefficients are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=default).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 10 Jul 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:09:04</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 10 Jul 2017   Pseudo R-squ.:                  0.4594\n",
       "Time:                        13:09:04   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error without validation set\n",
    "This is an in-sample prediction. Training error in both sklearn and statsmodels. Both are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97370000000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97370000000000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((result.predict(X) > .5) * 1 == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-11.44956312]), array([[  5.66688138e-03,   1.75292951e-05]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "model.fit(X_train, y_train)\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sm = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079055\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td>  7500</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  7497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 10 Jul 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.4640</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:09:08</td>     <th>  Log-Likelihood:    </th>  <td> -592.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1106.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.251e-223</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.4762</td> <td>    0.495</td> <td>  -23.195</td> <td> 0.000</td> <td>  -12.446</td> <td>  -10.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0057</td> <td>    0.000</td> <td>   21.659</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 1.769e-05</td> <td> 5.74e-06</td> <td>    3.083</td> <td> 0.002</td> <td> 6.44e-06</td> <td> 2.89e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                 7500\n",
       "Model:                          Logit   Df Residuals:                     7497\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 10 Jul 2017   Pseudo R-squ.:                  0.4640\n",
       "Time:                        13:09:08   Log-Likelihood:                -592.92\n",
       "converged:                       True   LL-Null:                       -1106.2\n",
       "                                        LLR p-value:                1.251e-223\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.4762      0.495    -23.195      0.000     -12.446     -10.506\n",
       "balance        0.0057      0.000     21.659      0.000       0.005       0.006\n",
       "income      1.769e-05   5.74e-06      3.083      0.002    6.44e-06    2.89e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=X_train_sm).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97360000000000002, 0.97360000000000002)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearly the same as training set. So not too much over fitting has happened\n",
    "(model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error of only .0272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079706\n",
      "         Iterations 10\n",
      "0.976 0.976\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.077230\n",
      "         Iterations 10\n",
      "0.9728 0.9728\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.077871\n",
      "         Iterations 10\n",
      "0.9712 0.9708\n"
     ]
    }
   ],
   "source": [
    "# c) repeat for 3 different validation sets\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_sm = X_train.join(y_train)\n",
    "    result = smf.logit(formula='default_yes ~ balance + income', data=X_train_sm).fit()\n",
    "    print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080539\n",
      "         Iterations 10\n",
      "0.9752 0.9752\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.074620\n",
      "         Iterations 10\n",
      "0.9716 0.9716\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.076308\n",
      "         Iterations 10\n",
      "0.9708 0.9708\n"
     ]
    }
   ],
   "source": [
    "# d) include student in model\n",
    "X = default[['balance', 'income', 'student_yes']]\n",
    "y = default['default_yes']\n",
    "\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_sm = X_train.join(y_train)\n",
    "    result = smf.logit(formula='default_yes ~ balance + income + student_yes', data=X_train_sm).fit()\n",
    "    print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like error rate is very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "Computing stand errors of coefficents of logistic regression using bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 30 Aug 2016</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:52:28</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393   -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05  3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 30 Aug 2016   Pseudo R-squ.:                  0.4594\n",
       "Time:                        12:52:28   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000       -12.393   -10.688\n",
       "balance        0.0056      0.000     24.835      0.000         0.005     0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000       1.1e-05  3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=default).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(columns=['Intercept', 'balance', 'income'])\n",
    "for i in range(100):\n",
    "    default_sample = default.sample(len(default), replace=True)\n",
    "    result_sample = smf.logit(formula='default_yes ~ balance + income', data=default_sample).fit(disp=0)\n",
    "    df_params = df_params.append(result_sample.params, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Intercept   -11.575038\n",
       " balance       0.005661\n",
       " income        0.000021\n",
       " dtype: float64, Intercept    0.379629\n",
       " balance      0.000194\n",
       " income       0.000005\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bootstrap parameters and standard error\n",
    "df_params.mean(), df_params.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Intercept   -11.540468\n",
       " balance       0.005647\n",
       " income        0.000021\n",
       " dtype: float64, Intercept    0.434772\n",
       " balance      0.000227\n",
       " income       0.000005\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model parameters and standard error\n",
    "result.params, result.bse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard errors are a wee bit higher in bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\n",
    "a) Fit Logistic Regression with Lag1, Lag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekly = pd.read_csv('data/weekly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly['Direction_Up'] = (weekly['Direction'] == 'Up').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Direction_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction  \\\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down   \n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down   \n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up   \n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up   \n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up   \n",
       "\n",
       "   Direction_Up  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weekly[['Lag1', 'Lag2']]\n",
    "y = weekly['Direction_Up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=1e-07, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.22122405]), array([[-0.03872222,  0.0602483 ]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55555555555555558"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(model.predict(X) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Fit without first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.22324304]),\n",
       " array([[-0.03843317,  0.06084763]]),\n",
       " 0.55647382920110189)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model is different but nearly identical\n",
    "model.fit(X.iloc[1:], y.iloc[1:])\n",
    "model.intercept_, model.coef_, (model.predict(X) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "# wrong prediction\n",
    "model.predict([X.iloc[0]]), y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n",
    "errors = np.zeros(len(X))\n",
    "for i in range(len(X)):\n",
    "    leave_out  = ~X.index.isin([i])\n",
    "    model.fit(X[leave_out], y[leave_out])\n",
    "    if model.predict([X.iloc[i]]) != y[i]:\n",
    "        errors[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44995408631772266"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e\n",
    "errors.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "y = x - 2*x**2 + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ubxapp9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a2a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>x</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.624345</td>\n",
       "      <td>2.638498</td>\n",
       "      <td>4.285832</td>\n",
       "      <td>6.961671</td>\n",
       "      <td>-4.099779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>0.374246</td>\n",
       "      <td>-0.228947</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>-0.135741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>0.278965</td>\n",
       "      <td>-0.147342</td>\n",
       "      <td>0.077822</td>\n",
       "      <td>-0.682611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>1.151262</td>\n",
       "      <td>-1.235268</td>\n",
       "      <td>1.325403</td>\n",
       "      <td>-2.781913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.648130</td>\n",
       "      <td>0.560897</td>\n",
       "      <td>-1.727365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    b0         x        x2        x3        x4         y\n",
       "0  1.0  1.624345  2.638498  4.285832  6.961671 -4.099779\n",
       "1  1.0 -0.611756  0.374246 -0.228947  0.140060 -0.135741\n",
       "2  1.0 -0.528172  0.278965 -0.147342  0.077822 -0.682611\n",
       "3  1.0 -1.072969  1.151262 -1.235268  1.325403 -2.781913\n",
       "4  1.0  0.865408  0.748930  0.648130  0.560897 -1.727365"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array([np.ones(len(x)), x, x ** 2, x ** 3, x ** 4, y]).T, columns=['b0', 'x', 'x2', 'x3', 'x4', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :5]\n",
    "y = df['y']\n",
    "model = LinearRegression()\n",
    "errors = np.zeros((len(X), 4))\n",
    "for i in range(len(X)):\n",
    "    leave_out  = ~X.index.isin([i])\n",
    "    for j in range(4):\n",
    "        model.fit(X.iloc[leave_out, :j+2], y[leave_out])\n",
    "        errors[i, j] = (model.predict([X.iloc[i, :j+2]]) - y[i]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.26076433,  0.91428971,  0.92687688,  0.86691169])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each error here is average error for linear, quadratic, cubic and quartic model.\n",
    "# Looks like it stabilizes at quadratic.\n",
    "errors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.61020827,   1.26528394,   1.28204182,   1.31659158])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again with different seed. \n",
    "np.random.seed(2)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "y = x - 2*x**2 + e\n",
    "df = pd.DataFrame(np.array([np.ones(len(x)), x, x ** 2, x ** 3, x ** 4, y]).T, columns=['b0', 'x', 'x2', 'x3', 'x4', 'y'])\n",
    "\n",
    "\n",
    "X = df.iloc[:, :5]\n",
    "y = df['y']\n",
    "model = LinearRegression()\n",
    "errors = np.zeros((len(X), 4))\n",
    "for i in range(len(X)):\n",
    "    leave_out  = ~X.index.isin([i])\n",
    "    for j in range(4):\n",
    "        model.fit(X.iloc[leave_out, :j+2], y[leave_out])\n",
    "        errors[i, j] = (model.predict([X.iloc[i, :j+2]]) - y[i]) ** 2\n",
    "\n",
    "# quite a different average error. But again stabilizes at quadratic which makes sense\n",
    "errors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f \n",
    "since the error doesn't improve after quadratic it's likely the \n",
    "standard errors for x3 and x4 would not be significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('data/boston.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110698"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a\n",
    "boston['medv'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4088611474975351"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b \n",
    "# standard deviation of mean\n",
    "boston['medv'].std() / np.sqrt(len(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42520687176372296"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c\n",
    "#bootstrap standard deviation of mean\n",
    "means = [boston['medv'].sample(n = len(boston), replace=True).mean() for i in range(1000)]\n",
    "np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.682392580583251, 23.383220067638145)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d\n",
    "se = np.std(means)\n",
    "boston['medv'].mean() - 2 * se, boston['medv'].mean() + 2 * se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.729528014578616, 23.336084633642781)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(boston['medv'])-1, loc=np.mean(boston['medv']), scale=st.sem(boston['medv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e\n",
    "boston['medv'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3836261070365255"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f\n",
    "medians = [boston['medv'].sample(n = len(boston), replace=True).median() for i in range(1000)]\n",
    "np.std(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g\n",
    "boston['medv'].quantile(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50031521064225093"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h\n",
    "quantile_10 = [boston['medv'].sample(n = len(boston), replace=True).quantile(.1) for i in range(1000)]\n",
    "np.std(quantile_10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
